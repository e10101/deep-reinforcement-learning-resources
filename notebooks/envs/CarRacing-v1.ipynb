{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CarRacing-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Easiest continuous control task to learn from pixels, a top-down\n",
    "racing environment. Discreet control is reasonable in this environment as\n",
    "well, on/off discretisation is fine.\n",
    "\n",
    "The game is solved when the agent consistently gets 900+ points.\n",
    "The generated track is random every episode.\n",
    "\n",
    "Some indicators are shown at the bottom of the window along with the\n",
    "state RGB buffer. From left to right: true speed, four ABS sensors,\n",
    "steering wheel position, gyroscope.\n",
    "To play yourself (it's rather fast for humans), type:\n",
    "```\n",
    "python gym/envs/box2d/car_racing.py\n",
    "```\n",
    "Remember it's a powerful rear-wheel drive car - don't press the accelerator\n",
    "and turn at the same time.\n",
    "\n",
    "## Action Space\n",
    "There are 3 actions: steering (-1 is full left, +1 is full right), gas,\n",
    "and breaking.\n",
    "\n",
    "## Observation Space\n",
    "State consists of 96x96 pixels.\n",
    "\n",
    "## Rewards\n",
    "The reward is -0.1 every frame and +1000/N for every track tile visited,\n",
    "where N is the total number of tiles visited in the track. For example,\n",
    "if you have finished in 732 frames, your reward is\n",
    "1000 - 0.1*732 = 926.8 points.\n",
    "\n",
    "## Starting State\n",
    "The car starts stopped at the center of the road.\n",
    "\n",
    "## Episode Termination\n",
    "The episode finishes when all the tiles are visited. The car also can go\n",
    "outside of the playfield - that is far off the track, then it will\n",
    "get -100 and die.\n",
    "\n",
    "## Arguments\n",
    "There are no arguments supported in constructing the environment.\n",
    "\n",
    "## Version History\n",
    "- v0: Current version\n",
    "\n",
    "## References\n",
    "- Chris Campbell (2014), http://www.iforce2d.net/b2dtut/top-down-car.\n",
    "\n",
    "## Credits\n",
    "Created by Oleg Klimov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Box2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib\n",
    "import PIL\n",
    "import pyvirtualdisplay\n",
    "\n",
    "from PIL import ImageDraw, ImageFont\n",
    "\n",
    "from absl import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from gym.envs.toy_text.taxi import MAP as taxi_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_env(policy=lambda s: env.action_space.sample(), sleep_time=0.1, env_seed=None):\n",
    "    \n",
    "    if env_seed is not None:\n",
    "        env.seed(env_seed)\n",
    "\n",
    "    states = []\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    state = env.reset()\n",
    "    states.append(state)\n",
    "    max_steps = env.spec.max_episode_steps\n",
    "    total_reward = 0\n",
    "    is_done = False\n",
    "    current_step = 0\n",
    "\n",
    "    while is_done == False:\n",
    "        # Get a random action\n",
    "        action = policy(state)\n",
    "\n",
    "        state, reward, is_done, info = env.step(action)\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "\n",
    "        total_reward += reward\n",
    "        current_step += 1\n",
    "\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # Print header\n",
    "        print('Step: {:03d}/{}, Reward: {}\\n'.format(\n",
    "            current_step,\n",
    "            max_steps,\n",
    "            total_reward,\n",
    "        ))\n",
    "        env.render()\n",
    "\n",
    "        time.sleep(sleep_time)\n",
    "        \n",
    "        \n",
    "    if current_step < max_steps:\n",
    "        print('\\nResult: Done with {} steps and total reward is {}.'.format(\n",
    "            current_step,\n",
    "            total_reward,\n",
    "        ))\n",
    "    else:\n",
    "        print('\\nResult: Unsolved')\n",
    "        \n",
    "    return states, rewards, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, rewards, actions = play_env(sleep_time=0.01, env_seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.from_array(a_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_frame = states[0]\n",
    "a_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in states:\n",
    "    img = PIL.Image.fromarray(frame)\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit: https://towardsdatascience.com/reinforcement-learning-teach-a-taxi-cab-to-drive-around-with-q-learning-9913e611028f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table_shape = [env.observation_space.n, env.action_space.n]\n",
    "learning_rate = 0.1  # Learning rate, i.e. alpha\n",
    "discount_factor = 0.99  # Discount factor, i.e. gamma\n",
    "epsilon = 0.1  # Exploring vs exploiting\n",
    "training_episodes = 100_000\n",
    "# training_episodes = 1000\n",
    "env_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the q-table with zero values\n",
    "q_table = np.zeros(q_table_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(training_episodes)):\n",
    "    # Reset the environment first\n",
    "    # env.seed(env_seed)\n",
    "    state = env.reset()\n",
    "    \n",
    "    # env.seed(i)\n",
    "    \n",
    "    # print('state', state)\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        if rng.random() < epsilon:\n",
    "            action = env.action_space.sample()  # Explore the action space (with a random action)\n",
    "        else:\n",
    "            action = np.argmax(q_table[state]) # Exploit leared values\n",
    "\n",
    "        # Apply the action and see what happens\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        # print(i, next_state, reward, done, info)\n",
    "\n",
    "        current_value = q_table[state, action]  # Current Q-value for the state-action pair\n",
    "        next_max = np.max(q_table[next_state])  # Next best Q-value\n",
    "\n",
    "        q_table[state, action] = (1 - learning_rate) * current_value + learning_rate * (reward + discount_factor * next_max)\n",
    "        # print(i, state, action, q_table[state, action])\n",
    "        \n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_env(\n",
    "    policy=lambda s: np.argmax(q_table[s]),\n",
    "    sleep_time=0.5,\n",
    "    env_seed=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, rewards, actions = play_env(\n",
    "    policy=lambda s: np.argmax(q_table[s]),\n",
    "    sleep_time=0.25,\n",
    "    env_seed=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, rewards, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_txt(char_row, char_col, char='â–ˆ'):\n",
    "    txt = ''\n",
    "    for r in range(char_row+2):\n",
    "        for c in range(char_col * 2 + 2):\n",
    "            if (char_row + 1) == r and (char_col * 2 + 1) == c:\n",
    "                txt += char\n",
    "            else:\n",
    "                txt += ' '\n",
    "        txt += '\\n'\n",
    "    \n",
    "    return txt\n",
    "\n",
    "def get_char_by_index(idx: int):\n",
    "    if idx == 0:\n",
    "        return 'R'\n",
    "    elif idx == 1:\n",
    "        return 'G'\n",
    "    elif idx == 2:\n",
    "        return 'Y'\n",
    "    elif idx == 3:\n",
    "        return 'B'\n",
    "    elif idx == 4:\n",
    "        return '_'\n",
    "    \n",
    "    return ' '\n",
    "\n",
    "def get_char_pos_by_index(idx: int, taxi_row: int, taxi_col: int):\n",
    "    if idx == 0:\n",
    "        return [0, 0]\n",
    "    elif idx == 1:\n",
    "        return [0, 4]\n",
    "    elif idx == 2:\n",
    "        return [4, 0]\n",
    "    elif idx == 3:\n",
    "        return [4, 3]\n",
    "    \n",
    "    return [taxi_row, taxi_col]\n",
    "\n",
    "def get_char_color_by_index(idx: int):\n",
    "    if idx == 0:\n",
    "        return (255, 0, 0) # Red\n",
    "    elif idx == 1:\n",
    "        return (0, 255, 0) # Green\n",
    "    elif idx == 2:\n",
    "        return (255, 255, 0) # Yellow\n",
    "    elif idx == 3:\n",
    "        return (0, 0, 255) # Blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_frame(frame: np.ndarray, main_text=None, state=None, side_text=None, done=False) -> np.ndarray:\n",
    "    if main_text is None:\n",
    "        return frame\n",
    "    \n",
    "    # Convert array to PIl.Image\n",
    "    image = PIL.Image.fromarray(frame).convert('RGB')\n",
    "\n",
    "    # Get draw context\n",
    "    draw = ImageDraw.Draw(image, 'RGB')\n",
    "\n",
    "    # Get font\n",
    "    font_file = '/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf'\n",
    "    font = ImageFont.truetype(font_file, 24)\n",
    "    \n",
    "    # Variables\n",
    "    draw_offset = (30, 30)\n",
    "    side_offset = (220, 30)\n",
    "    side_font_size = 20\n",
    "    side_font = ImageFont.truetype(font_file, side_font_size)\n",
    "    taxi_color = (255, 255, 0)\n",
    "    passenger_color = (0, 0, 255)\n",
    "    dest_color = (255, 0, 255)\n",
    "    taxi_with_passenger_color = (0, 255, 0)\n",
    "    \n",
    "    # Render state\n",
    "    if state is not None:\n",
    "        # Draw taxi (color background)\n",
    "        [taxi_row, taxi_col, passenger_location, destination] = list(env.decode(state))\n",
    "        print([taxi_row, taxi_col, passenger_location, destination])\n",
    "        taxi_txt = get_char_txt(taxi_row, taxi_col)\n",
    "        \n",
    "        taxi_color = taxi_with_passenger_color if (passenger_location == 4 and not done) else taxi_color \n",
    "        draw.text(draw_offset, taxi_txt, font=font, fill=taxi_color, stroke_width=1, stroke_fill=(100, 100, 100))\n",
    "        \n",
    "        # Draw map\n",
    "        draw.text(draw_offset, main_text, font=font, fill=(0, 0, 0), stroke_width=1, stroke_fill=(255, 255, 255))\n",
    "        \n",
    "        # Draw passenger\n",
    "        passenger_char = get_char_by_index(passenger_location)\n",
    "        [passenger_row, passenger_col] = get_char_pos_by_index(passenger_location, taxi_row, taxi_col)\n",
    "        passenger_txt = get_char_txt(passenger_row, passenger_col, char=passenger_char)\n",
    "        # passenger_color = get_char_color_by_index(passenger_location)\n",
    "        # print('passenger_txt', passenger_txt)\n",
    "        draw.text(draw_offset, passenger_txt, font=font, fill=passenger_color, stroke_width=1, stroke_fill=(255, 255, 255))\n",
    "        \n",
    "        # Draw destination\n",
    "        dest_char = get_char_by_index(destination)\n",
    "        [dest_row, dest_col] = get_char_pos_by_index(destination, taxi_row, taxi_col)\n",
    "        dest_txt = get_char_txt(dest_row, dest_col, char=dest_char)\n",
    "        # dest_color = get_char_color_by_index(destination)\n",
    "        # print('dest_txt', dest_txt)\n",
    "        draw.text(draw_offset, dest_txt, font=font, fill=dest_color, stroke_width=1, stroke_fill=(255, 255, 255))\n",
    "        \n",
    "    else:\n",
    "        # Draw background\n",
    "        draw.text(draw_offset, main_text, font=font, fill=(0, 0, 0), stroke_width=1, stroke_fill=(255, 255, 255))\n",
    "    \n",
    "    if side_text is not None:\n",
    "        draw.text(side_offset, side_text, font=side_font, fill=(0, 0, 0), stroke_width=1, stroke_fill=(255, 255, 255))\n",
    "\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'Taxi-v3'\n",
    "def create_states_video(\n",
    "    states, rewards, filename=None, fps=30, \n",
    "    env_name=env_name, freeze_seconds=0, freeze_begin_seconds=0, step=None):\n",
    "    if filename is None:\n",
    "        filename = str(get_timestamp())\n",
    "        \n",
    "    filename = filename + '.mp4'\n",
    "    logging.info('Env: %s', env_name)\n",
    "    logging.info('Filename: %s', filename)\n",
    "    map_txt = '\\n'.join(taxi_map)\n",
    "\n",
    "    with imageio.get_writer(filename, fps=fps) as video:\n",
    "        logging.info('Begin')\n",
    "        total_reward = 0.0\n",
    "        frame_idx = 0\n",
    "                \n",
    "        for idx, (state, reward, action) in enumerate(zip(states, rewards, actions)):\n",
    "            done = reward == 20\n",
    "            # Freeze frame for a few seconds - At beginning\n",
    "            if idx == 0 and freeze_begin_seconds > 0:\n",
    "                text = f'Env: {env_name}'\n",
    "                if step is not None:\n",
    "                    text += f'\\nStp: {step}'\n",
    "                text += f'\\nFrm: {frame_idx}'\n",
    "                text += f'\\nRw:  {total_reward:.2f}'\n",
    "\n",
    "                frame = np.full((270, 480), 240.0)\n",
    "                frame = enhance_frame(frame, '{}'.format(map_txt), side_text=text, state=state)\n",
    "\n",
    "                for _ in range(fps * freeze_begin_seconds):\n",
    "                    video.append_data(frame)\n",
    "\n",
    "            action_name = action_names[action]\n",
    "            \n",
    "            total_reward += reward\n",
    "            \n",
    "            text = f'Env: {env_name}'\n",
    "            if step is not None:\n",
    "                text += f'\\nStp: {step}'\n",
    "            text += f'\\nFrm: {frame_idx}'\n",
    "            text += f'\\nRw:  {total_reward:.2f}'\n",
    "            text += f'\\nAct: {action_name}'\n",
    "            \n",
    "            if done:\n",
    "                text += f'\\n\\nDone!\\nFeb 13, 2022'\n",
    "\n",
    "            frame = np.full((270, 480), 240.0)\n",
    "            frame = enhance_frame(frame, '{}'.format(map_txt), side_text=text, state=state, done=done)\n",
    "            \n",
    "            video.append_data(frame)\n",
    "            \n",
    "            frame_idx += 1\n",
    "            \n",
    "            # Freeze frame for a few seconds\n",
    "            if frame_idx+1 >= len(states) and freeze_seconds > 0:\n",
    "                for _ in range(fps * freeze_seconds):\n",
    "                    video.append_data(frame)\n",
    "\n",
    "    logging.info('All done')\n",
    "    return filename\n",
    "    # return embed_mp4(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_states_video(states, rewards, filename='taxi', fps=2, env_name='Taxi-v3', freeze_seconds=3, freeze_begin_seconds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
